{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jackknife\n",
    "\n",
    "Suponga que se tiene una muestra de variables independientes e indénticamente distribuidas $\\mathbf{x}=(x_1,\\ldots,x_n)$ que provienen de una distribución $F$ que no se conoce. \n",
    "\n",
    "Utilizando $\\mathbf{x}$, se estima una cantidad de interés $\\theta$ a través de un algoritmo $A$.\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = A(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Si la distribución $F$ fuera conocida, se podría estimar el error estándar de $\\hat{\\theta}$ generando nuevas muestras $\\mathbf{x}$ obteniendo un conjunto $\\hat{\\theta_1}, \\hat{\\theta_2}, \\ldots, \\hat{\\theta_m}$ de estimaciones de $\\theta$, el error estándar se calcularía obteniendo la desviación estándar de estas estimaciones.\n",
    "\n",
    "Al no conocer $F$, la metodología de **jackknife** propone estimar el error estándar de la siguiente forma:\n",
    "\n",
    "Sea $\\mathbf{x_{(i)}} = (x_1, \\ldots, x_{i-1},x_{i+1},\\ldots,x_n)$ la muestra $\\mathbf{x}$ sin incluir la $i$-ésima observación. Si $\\hat{\\theta_{(i)}} = A(\\mathbf{x_{(i)}})$ denota el valor estimado de nuestra cantidad de interés, entonces el estimado del erro estándar está dado por\n",
    "\n",
    "$$\n",
    "\\widehat{se}_{jack} = \\sqrt{ \\dfrac{n-1}{n} \\sum_{i=1}^{n} \\left(\\hat{\\theta_{(i)}} - \\hat{\\theta_{(*)}}   \\right)^2  }\n",
    "$$\n",
    "\n",
    "en donde $\\hat{\\theta_{(*)}} = \\sum_{i=1}^{n} \\dfrac{\\hat{\\theta_{(i)}}}{n}$\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "Simule 60 variables $N(\\mu=2,\\sigma=1)$ y programe una función para calcular el error estándar, utilizando jackknife, al estimar $\\mu$ a través del promedio.\n",
    "\n",
    "Compare este error con la desviación estándar realizando el procedimiento descrito si se conociera la distribución $F$. Utilice $1e4$ simulaciones.\n",
    "\n",
    "\n",
    "**Observación**\n",
    "\n",
    "A pesar de que en este ejercicio se considera que $\\mathbf{x}$ es una muestra de números reales, la metodología funciona también para otro tipo de objetos, por ejemplo muestras de vectores en $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def algoritmo(x):\n",
    "    '''\n",
    "    Algoritmo para estimar un parámetro a partir\n",
    "    de una muestra\n",
    "    \n",
    "    ENTRADA\n",
    "    x: Numpy array\n",
    "    \n",
    "    SALIDA\n",
    "    Estimación de nuestro parámetro de interés\n",
    "    '''\n",
    "    return np.mean(x)\n",
    "\n",
    "def jackkife_se(x, algoritmo):\n",
    "    '''\n",
    "    Función para calcular el error estándar utilizando\n",
    "    la metodología de jackknife\n",
    "    \n",
    "    ENTRADA\n",
    "    x: Numpy array 1D que representa la muestra\n",
    "    \n",
    "    algoritmo: Función que calcula el parámetro de\n",
    "    interés\n",
    "    \n",
    "    SALIDA\n",
    "    estimados: numpy array con el parámetro estimado para cada muestra\n",
    "    se: Estimación del error estándar para el parámetro\n",
    "    de interés\n",
    "    '''\n",
    "    \n",
    "    #Número de obervaciones\n",
    "    n_obs = len(x)\n",
    "    \n",
    "    #Para almacenar los estimados al quitar x_i\n",
    "    estimados = []\n",
    "    \n",
    "    for i in range(n_obs):\n",
    "        \n",
    "        #Quita la observación x_i\n",
    "        muestra = np.concatenate((x[0:i], x[i+1:]))\n",
    "        \n",
    "        #calcula el estimado\n",
    "        estimados.append(algoritmo(muestra))\n",
    "    \n",
    "    #calcula el error estándar estimado\n",
    "    se = np.sqrt((n_obs - 1)*np.var(estimados, ddof = 0))\n",
    "    \n",
    "    return np.array(estimados), se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error estándar de jackknife es 0.11438\n",
      "El error estándar conociendo F es 0.12945\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(54321)\n",
    "size_muestra = 60\n",
    "#muestra para jackknife\n",
    "x_jack = norm.rvs(size = size_muestra, loc = 2, scale = 1)\n",
    "\n",
    "#Error estándar estimado\n",
    "estimados_jack, se_jack = jackkife_se(x_jack, algoritmo)\n",
    "\n",
    "#Ahora simulamos como si se conociera F\n",
    "x_F = norm.rvs(size = (int(1e4), size_muestra), loc = 2, scale = 1)\n",
    "\n",
    "estimados_F = np.apply_along_axis(algoritmo, axis = 1, arr = x_F)\n",
    "se_F = np.std(estimados_F,ddof=0)\n",
    "\n",
    "print('El error estándar de jackknife es', np.round(se_jack,5))\n",
    "print('El error estándar conociendo F es', np.round(se_F,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "\n",
    "El estimado del error estándar utilizando la metodología de bootstrap se basa en, a partir de una muestra inicial $\\mathbf{x}=(x_1,x_2,\\ldots,x_n)$ obtener nuevas muestras\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^{*} = (x_{1}^{*},x_{2}^{*},\\ldots,x_{n}^{*})\n",
    "$$\n",
    "\n",
    "en donde cada $x_{i}^{*}$ se obtiene a través de una extracción equiprobable y con reemplazo del conjunto $\\{ x_1, x_2, \\ldots, x_n\\}$.\n",
    "\n",
    "Para cada muestra $\\mathbf{x}^{*}$ obtenemos un estimado $\\hat{\\theta^{*b}}$ de nuestro parámetro de interés.\n",
    "\n",
    "Si $B$ denota el número de muestras $\\mathbf{x^*}$, el estimado para el error estándar es\n",
    "\n",
    "$$\n",
    "\\hat{se}_{boot} = \\sqrt{ \\dfrac{\\sum_{i=1}^{B} \\left(\\hat{\\theta^{*b}} - \\hat{\\theta^{*}} \\right)^2}{B-1} }\n",
    "$$\n",
    "\n",
    "en donde \n",
    "$$\n",
    "\\hat{\\theta^{*}} = \\dfrac{1}{B}\\sum_{i=1}^{B} \\hat{\\theta^{*b}}\n",
    "$$\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "Simule 60 variables $N(\\mu=2,\\sigma=1)$ y programe una función para calcular el error estándar, utilizando bootstrap, al estimar $\\mu$ a través del promedio.\n",
    "\n",
    "Compare este error con la desviación estándar realizando el procedimiento descrito si se conociera la distribución $F$. Utilice $1e4$ simulaciones.\n",
    "\n",
    "$B=1000$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def algoritmo(x):\n",
    "    '''\n",
    "    Algoritmo para estimar un parámetro a partir\n",
    "    de una muestra\n",
    "    \n",
    "    ENTRADA\n",
    "    x: Numpy array\n",
    "    \n",
    "    SALIDA\n",
    "    Estimación de nuestro parámetro de interés\n",
    "    '''\n",
    "    return np.mean(x)\n",
    "\n",
    "def bootstrap_se(x, algoritmo, B = 1000):\n",
    "    '''\n",
    "    Función para calcular el error estándar utilizando\n",
    "    la metodología de bootstrap\n",
    "    \n",
    "    ENTRADA\n",
    "    x: Numpy array 1D que representa la muestra original\n",
    "    \n",
    "    algoritmo: Función que calcula el parámetro de\n",
    "    interés\n",
    "    \n",
    "    B: Entero positivo que representa el número de\n",
    "    muestras bootstrap\n",
    "    \n",
    "    SALIDA\n",
    "    estimados: numpy array con el parámetro estimado para cada muestra\n",
    "    se: Estimación del error estándar para el parámetro\n",
    "    de interés\n",
    "   '''\n",
    "    #Para almacenar los estimados de cada muestra\n",
    "    estimados = []\n",
    "    \n",
    "    for i in range(B):\n",
    "        \n",
    "        #Obtiene muestra con reemplazo\n",
    "        muestra = np.random.choice(a = x, size = len(x), replace = True)\n",
    "\n",
    "        #calcula el estimado\n",
    "        estimados.append(algoritmo(muestra))\n",
    "    \n",
    "    #calcula el error estándar estimado\n",
    "    se = np.std(estimados,ddof=1)\n",
    "    \n",
    "    return np.array(estimados), se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error estándar de bootstrap es 0.11473\n",
      "El error estándar conociendo F es 0.12013\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(54321)\n",
    "boot_muestra = 70\n",
    "#muestra para jackknife\n",
    "x_boot = norm.rvs(size = size_muestra, loc = 2, scale = 1)\n",
    "\n",
    "#Error estándar estimado\n",
    "estimados_boot, se_boot = bootstrap_se(x_boot, algoritmo, B = boot_muestra)\n",
    "\n",
    "#Ahora simulamos como si se conociera F\n",
    "x_F = norm.rvs(size = (int(1e4), boot_muestra), loc = 2, scale = 1)\n",
    "\n",
    "estimados_F = np.apply_along_axis(algoritmo, axis = 1, arr = x_F)\n",
    "se_F = np.std(estimados_F,ddof=0)\n",
    "\n",
    "print('El error estándar de bootstrap es', np.round(se_boot,5))\n",
    "print('El error estándar conociendo F es', np.round(se_F,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.026573076310199, 2.4529342639891354)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construcción del intervalo del 95%\n",
    "(np.quantile(estimados_boot, q = 0.025), np.quantile(estimados_boot, q = 0.975) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2194100448841416"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimados_boot.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
